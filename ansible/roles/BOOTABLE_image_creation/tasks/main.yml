---
# tasks file for BOOTABLE
- name: Upgrade all packages
  yum:
    name: '*'
    state: latest
  become: yes

- name: Reboot immediately
  shell: "sleep 5 && reboot"
  async: 1
  poll: 0
  become: yes

- name: Wait for the reboot to complete
  wait_for_connection:
    connect_timeout: 20
    sleep: 5
    delay: 5
    timeout: 300

- name: Install EPEL
  yum:
    name: epel-release
    state: latest
    disable_gpg_check: 1
  become: yes

- name: install the 'Development tools' package group
  yum:
    name: "@Development tools"
    state: present
    disable_gpg_check: 1
  become: yes


- name: Install packages
  with_items: "{{ common_packages | mandatory }}"
  yum:
    name: "{{ item }}"
    state: latest
    disable_gpg_check: 1
  become: yes

- name: Install R - packages
  command: >
    Rscript --slave --no-save --no-restore-history -e "if (! ('{{ item }}' %in% installed.packages()[,'Package'])) { install.packages(pkgs='{{ item }}', repos=c('http://ftp.heanet.ie/mirrors/cran.r-project.org/')); print('Added'); } else { print('Already installed'); }"
  register: r_result
  failed_when: "r_result.rc != 0 or 'had non-zero exit status' in r_result.stderr"
  changed_when: "'Added' in r_result.stdout"
  with_items:
    - grid
    - gridExtra
    - RColorBrewer
    - stringr
  become: yes

- name: Get number of maximal available cores
  shell: echo $(nproc)
  register: nproc_number


###########################################
### Create benchmark output directories ###
###########################################
- name: Create empty benchmark output directory
  file:
    path: "{{ root_path }}benchmark_output/"
    state: directory

- name: Create empty bowtie2 output directory
  file:
    path: "{{ root_path }}benchmark_output/bowtie2/"
    state: directory

- name: Create empty clustal Omega output directory
  file:
    path: "{{ root_path }}benchmark_output/clustalOmega/"
    state: directory

- name: Create empty GROMACS output directory
  file:
    path: "{{ root_path }}benchmark_output/gromacs/"
    state: directory

- name: Create empty IDBA output directory
  file:
    path: "{{ root_path }}benchmark_output/IDBA/"
    state: directory

- name: Create empty SPAdes output directory
  file:
    path: "{{ root_path }}benchmark_output/SPAdes/"
    state: directory

- name: Create empty tensorflow output directory
  file:
    path: "{{ root_path }}benchmark_output/tensorflow/"
    state: directory

- name: Create empty velvet output directory
  file:
    path: "{{ root_path }}benchmark_output/velvet/"
    state: directory


###############################
### Create Tool directories ###
###############################
- name: Create empty bowtie2 directory
  file:
    path: "{{ root_path }}bowtie2/"
    state: directory

- name: Create empty clustal Omega directory
  file:
    path: "{{ root_path }}clustalOmega/"
    state: directory

- name: Create empty GROMACS directory
  file:
    path: "{{ root_path }}gromacs/"
    state: directory

- name: Create empty GROMACS build directory
  file:
    path: "{{ root_path }}gromacs/gromacs-2018.3/build/"
    state: directory

- name: Create empty IDBA directory
  file:
    path: "{{ root_path }}IDBA/"
    state: directory

- name: Create empty SPAdes directory
  file:
    path: "{{ root_path }}SPAdes/"
    state: directory

- name: Create empty tensorflow directory
  file:
    path: "{{ root_path }}tensorflow/"
    state: directory

- name: Create empty velvet directory
  file:
    path: "{{ root_path }}velvet/"
    state: directory


##################################
### Create dataset directories ###
##################################
- name: Create empty dataset directory
  file:
    path: "{{ root_path }}datasets/"
    state: directory

- name: Create empty 1000 genomes directory
  file:
    path: "{{ root_path }}datasets/1000_genomes"
    state: directory

- name: Create empty clustal Omega dataset directory
  file:
    path: "{{ root_path }}datasets/clustalOmega"
    state: directory

- name: Create empty tensorflow data directory
  file:
    path: "{{ root_path }}datasets/tensorflow"
    state: directory

- name: Create empty gromacs data directory
  file:
    path: "{{ root_path }}datasets/gromacs"
    state: directory

- name: Create empty ebi dataset directory
  file:
    path: "{{ root_path }}datasets/ebi"
    state: directory

##########################################
### Create other necessary directories ###
##########################################
- name: Create empty results directory
  file:
    path: "{{ root_path }}results"
    state: directory

- name: Create empty back up directory
  file:
    path: "{{ root_path }}backed_up_benchmark_results"
    state: directory

- name: Create empty gcc directory
  file:
    path: "{{ root_path }}gcc"
    state: directory

- name: Create empty gcc-build directory
  file:
    path: "{{ root_path }}gcc/gcc-build"
    state: directory

- name: Create empty gcc/gcc-installed directory
  file:
    path: "{{ root_path }}gcc/gcc-installed"
    state: directory

- name: Create empty nmon_stats directory
  file:
    path: "{{ root_path }}nmon_stats"
    state: directory

#########################
### Download datasets ###
#########################
- name: Download read set ERR251006
  get_url:
    url:  https://s3.denbi.uni-tuebingen.de/max/ERR251006.filt.fastq.gz
    dest: "{{ root_path }}datasets/1000_genomes/ERR251006.filt.fastq.gz"

- name: Unarchive read set ERR251006
  command: gunzip "{{ root_path }}datasets/1000_genomes/ERR251006.filt.fastq.gz" creates="{{ root_path }}datasets/1000_genomes/ERR251006.filt.fastq"


- name: Download read set ERR016155
  get_url:
    url: https://s3.denbi.uni-tuebingen.de/max/ERR016155.filt.fastq.gz
    dest: "{{ root_path }}datasets/1000_genomes/ERR016155.filt.fastq.gz"

- name: Unarchive read set ERR016155
  command: gunzip "{{ root_path }}datasets/1000_genomes/ERR016155.filt.fastq.gz" creates="{{ root_path }}datasets/1000_genomes/ERR016155.filt.fastq"


- name: Download read set ERR015528
  get_url:
    url: https://s3.denbi.uni-tuebingen.de/max/ERR015528.filt.fastq.gz
    dest: "{{ root_path }}datasets/1000_genomes/ERR015528.filt.fastq.gz"

- name: Unarchive read set ERR015528
  command: gunzip "{{ root_path }}datasets/1000_genomes/ERR015528.filt.fastq.gz" creates="{{ root_path }}datasets/1000_genomes/ERR015528.filt.fastq"


- name: Download read set SRR741411
  get_url:
    url: https://s3.denbi.uni-tuebingen.de/max/SRR741411.filt.fastq.gz
    dest: "{{ root_path }}datasets/1000_genomes/SRR741411.filt.fastq.gz"

- name: Unarchive read set SRR741411
  command: gunzip "{{ root_path }}datasets/1000_genomes/SRR741411.filt.fastq.gz" creates="{{ root_path }}datasets/1000_genomes/SRR741411.filt.fastq"


- name: Download read set DRR001012
  get_url:
    url: https://s3.denbi.uni-tuebingen.de/max/DRR001012.fastq.gz
    dest: "{{ root_path }}datasets/ebi/DRR001012.fastq.gz"

- name: Unarchive read set DRR001012
  command: gunzip "{{ root_path }}datasets/ebi/DRR001012.fastq.gz" creates="{{ root_path }}datasets/ebi/DRR001012.fastq"


- name: Download read set DRR001025
  get_url:
    url: https://s3.denbi.uni-tuebingen.de/max/DRR001025.fastq.gz
    dest: "{{ root_path }}datasets/ebi/DRR001025.fastq.gz"

- name: Unarchive read set DRR001025
  command: gunzip "{{ root_path }}datasets/ebi/DRR001025.fastq.gz" creates="{{ root_path }}datasets/ebi/DRR001025.fastq"


- name: Download reference genome GRCh38
  get_url: 
    url: https://s3.denbi.uni-tuebingen.de/max/GRCh38_full_analysis_set_plus_decoy_hla.fa
    dest: "{{ root_path }}datasets/1000_genomes/GRCh38_full_analysis_set_plus_decoy_hla.fa"


- name: Download clustal Omega dataset wgs.ANCA.1_200
  get_url:
    url: https://s3.denbi.uni-tuebingen.de/max/wgs.ANCA.1_200.fsa
    dest: "{{ root_path }}datasets/clustalOmega/wgs.ANCA.1_200.fsa"


- name: Download clustal Omega dataset wgs.ANCA.1_400
  get_url:
    url: https://s3.denbi.uni-tuebingen.de/max/wgs.ANCA.1_400.fsa
    dest: "{{ root_path }}datasets/clustalOmega/wgs.ANCA.1_400.fsa"


- name: Download clustal Omega dataset wgs.ANCA.1_500
  get_url:
    url: https://s3.denbi.uni-tuebingen.de/max/wgs.ANCA.1_500.fsa
    dest: "{{ root_path }}datasets/clustalOmega/wgs.ANCA.1_500.fsa"


- name: Download and unarchive tensorflow models
  unarchive:
    src: https://s3.denbi.uni-tuebingen.de/max/models.tar.gz
    dest: "{{ root_path }}datasets/tensorflow/"
    remote_src: yes

- name: Download and unarchive tensorflow cifar-10-binary
  unarchive:
    src: https://s3.denbi.uni-tuebingen.de/max/cifar-10-binary.tar.gz
    dest: "{{ root_path }}datasets/tensorflow/"
    remote_src: yes

- name: Download tensorflow cifar-10-binary again, needs to be present as .tar.gz
  get_url:
    url: https://s3.denbi.uni-tuebingen.de/max/cifar-10-binary.tar.gz
    dest: "{{ root_path }}datasets/tensorflow/"


- name: Download and unarchive GROMACS dataset
  unarchive:
    src: https://s3.denbi.uni-tuebingen.de/max/ADH_bench_systems.tar.gz
    dest: "{{ root_path }}datasets/gromacs/"
    remote_src: yes

- name: Set nsteps value from 10000 to 50000 in 
  command: sed -i 's/nsteps.*/nsteps                  = 50000/' "{{ root_path }}datasets/gromacs/adh_cubic/pme_verlet.mdp"


#################################
### Download additional tools ###
#################################
- name: Download and unarchive GCC compiler version 7.3.0
  unarchive:
    src: https://s3.denbi.uni-tuebingen.de/max/gcc-7.3.0.tar.gz
    dest: "{{ root_path }}gcc/"
    remote_src: yes

- name: Download and unarchive nmonchart34
  unarchive:
    src: https://s3.denbi.uni-tuebingen.de/max/nmonchart34.tar
    dest: "{{ root_path }}"
    remote_src: yes

- name: Remove nmonchart34 tar archive after unarchiving
  file:
    state: absent
    path: "{{ root_path }}nmonchart34.tar"

##########################################
### Install gcc compiler version 7.3.0 ###
##########################################
- name: Install additional software for gcc compiler version 7.3.0
  command: ./contrib/download_prerequisites
  args:
    chdir: "{{ root_path }}gcc/gcc-7.3.0"

- name: Configure gcc compiler version 7.3.0
  command: ../gcc-7.3.0/configure --enable-languages=c,c++ --disable-multilib --prefix="{{ root_path }}gcc/gcc-installed"
  args:
    chdir: "{{ root_path }}gcc/gcc-build"

- name: Compile gcc compiler version 7.3.0
  make:
    chdir: "{{ root_path }}gcc/gcc-build"
    target: all
    params:
      NUM_THREADS: "{{ nproc_number.stdout }}"

- name: Install gcc compiler version 7.3.0
  make:
   chdir: "{{ root_path }}gcc/gcc-build"
   target: install

#######################
### Install bowtie2 ###
#######################
- name: Download and unarchive and install bowtie2 tool
  unarchive:
    src: https://s3.denbi.uni-tuebingen.de/max/bowtie2-2.3.4.2-source.zip
    dest: "{{ root_path }}bowtie2/"
    remote_src: yes
    creates: "{{ root_path }}bowtie2/*"

- name: Compile static libs for bowtie2
  make:
    chdir: "{{ root_path }}bowtie2/bowtie2-2.3.4.2/"
    target: static-libs

- name: Compile and install bowtie2
  make:
    chdir: "{{ root_path }}bowtie2/bowtie2-2.3.4.2/"
    target: all
    params:
      STATIC_BUILD: 1

######################
### Install velvet ###
######################
- name: Download velvet from git repo
  command: git clone https://github.com/dzerbino/velvet.git /home/centos/velvet/ creates=/home/centos/velvet/*

- name: Compile and install velvet
  make: 
    chdir: "{{ root_path }}velvet/"
    params:
      OPENMP: 1

####################
### Install IDBA ###
####################
- name: Download and unarchive IDBA tool in version 1.0.9
  unarchive:
    src: https://s3.denbi.uni-tuebingen.de/max/idba_ud-1.0.9.tar.gz
    dest: "{{ root_path }}IDBA/"
    remote_src: yes
    creates: "{{ root_path }}IDBA/*"

- name: Configure IDBA
  command: ./configure
  args:
    chdir: "{{ root_path }}IDBA/idba_ud-1.0.9/"

- name: Compile and install IDBA
  make:
    chdir: "{{ root_path }}IDBA/idba_ud-1.0.9/"

##################################
### Install pip and tensorflow ###
##################################
- name: Use pip install to install pip in Version 9.0.3
  pip:
    name: pip
    version: 9.0.3
    state: forcereinstall
  become: yes

- name: Use pip install to install tensorflow in version 1.4.0
  pip:
    name: tensorflow
    version: 1.4.0
  become: yes

#######################
### Install GROMACS ###
#######################
- name: Download and unarchive GROMACS 2018.3
  unarchive:
    src: https://s3.denbi.uni-tuebingen.de/max/gromacs-2018.3.tar.gz
    dest: "{{ root_path }}gromacs/"
    remote_src: yes
    creates: "{{ root_path }}gromacs/*"

- name: Prepare makefile for GROMACS with cmake3
  shell:  cd "{{ root_path }}gromacs/gromacs-2018.3/build/" && CC=gcc CXX=g++ cmake3 -DCMAKE_CXX_COMPILER=g++ -DGMX_BUILD_OWN_FFTW=on -DGMX_GPU=off -DGMX_BUILD_MPI=off --build ./ "{{ root_path }}gromacs/gromacs-2018.3/"
  environment:
    PATH: "{{ root_path }}gcc/gcc-installed/bin:{{ ansible_env.PATH}}"
    LD_LIBRARY_PATH: "{{ root_path }}gcc/gcc-installed/lib64/"

- name: Compile GROMACS
  make:
    chdir: "{{ root_path }}gromacs/gromacs-2018.3/build/"
    target: all
    params:
      NUM_THREADS: "{{ nproc_number.stdout }}"
  environment:
      PATH: "{{ root_path }}gcc/gcc-installed/bin:{{ ansible_env.PATH}}"
      LD_LIBRARY_PATH: "{{ root_path }}gcc/gcc-installed/lib64/" 

- name: Install GROMACS
  make:
    chdir: "{{ root_path }}gromacs/gromacs-2018.3/build/"
    target: install  
  become: yes

- name: Build input files for GROMACS on testdata adh_cubic
  command: /usr/local/gromacs/bin/gmx grompp -f "{{ root_path }}datasets/gromacs/adh_cubic/pme_verlet.mdp" -c "{{ root_path }}datasets/gromacs/adh_cubic/conf.gro" -p "{{ root_path }}datasets/gromacs/adh_cubic/topol.top" -o "{{ root_path }}datasets/gromacs/adh_cubic/topol" -po "{{ root_path }}datasets/gromacs/adh_cubic/mdout"
  environment:
      LD_LIBRARY_PATH: "{{ root_path }}gcc/gcc-installed/lib64/"

######################
### Install SPAdes ###
######################
- name: Download and unarchive SPAdes 3.12.0
  unarchive:
    src: https://s3.denbi.uni-tuebingen.de/max/SPAdes-3.12.0-Linux.tar.gz
    dest: "{{ root_path }}SPAdes/"
    remote_src: yes

#############################
### Install Clustal Omega ###
#############################
- name: Download and unarchive clustal Omega 1.2.4
  unarchive:
    src: https://s3.denbi.uni-tuebingen.de/max/clustal-omega-1.2.4.tar.gz
    dest: "{{ root_path }}clustalOmega"
    remote_src: yes

- name: Configure clustal Omega
  shell: cd "{{ root_path }}clustalOmega/clustal-omega-1.2.4/" && ./configure --prefix=$PWD

- name: Compile clustal Omega
  make:
    chdir: "{{ root_path }}clustalOmega/clustal-omega-1.2.4/"
    target: all
    params:
      NUM_THREADS: "{{ nproc_number.stdout }}"
  
- name: Install clustal Omega
  make:
    chdir: "{{ root_path }}clustalOmega/clustal-omega-1.2.4/"
    target: install


###################################################
### Convert datastes from fastq to fa with IDBA ###
###################################################
- name: Convert fastq to fasta data (ERR016155)
  command: "{{ root_path }}IDBA/idba_ud-1.0.9/bin/fq2fa {{ root_path }}datasets/1000_genomes/ERR016155.filt.fastq {{ root_path }}datasets/1000_genomes/ERR016155.filt.fa"

- name: Convert fastq to fasta data (ERR251006)
  command: "{{ root_path }}IDBA/idba_ud-1.0.9/bin/fq2fa {{ root_path }}datasets/1000_genomes/ERR251006.filt.fastq {{ root_path }}datasets/1000_genomes/ERR251006.filt.fa"

- name: Convert fastq to fasta data (ERR015528)
  command: "{{ root_path }}IDBA/idba_ud-1.0.9/bin/fq2fa {{ root_path }}datasets/1000_genomes/ERR015528.filt.fastq {{ root_path }}datasets/1000_genomes/ERR015528.filt.fa"

- name: Convert fastq to fasta data (SRR741411)
  command: "{{ root_path }}IDBA/idba_ud-1.0.9/bin/fq2fa {{ root_path }}datasets/1000_genomes/SRR741411.filt.fastq {{ root_path }}datasets/1000_genomes/SRR741411.filt.fa"

- name: Convert fastq to fasta data (DRR001012)
  command: "{{ root_path }}IDBA/idba_ud-1.0.9/bin/fq2fa {{ root_path }}datasets/ebi/DRR001012.fastq {{ root_path }}datasets/ebi/DRR001012.fa"

- name: Convert fastq to fasta data (DRR001025)
  command: "{{ root_path }}IDBA/idba_ud-1.0.9/bin/fq2fa {{ root_path }}datasets/ebi/DRR001025.fastq {{ root_path }}datasets/ebi/DRR001025.fa"

#############################
### Copy executable files ###
#############################
- name: Copy run_benchmarks.sh script to host
  copy:
    src: run_benchmarks.sh
    dest: "{{ root_path }}run_benchmarks.sh"

- name: Copy install_check.sh script to host
  copy:
    src: install_check.sh
    dest: "{{ root_path }}install_check.sh"

- name: Copy BOOTABLE_collect.sh script to host
  copy:
    src: BOOTABLE_collect.sh
    dest: "{{ root_path }}BOOTABLE_collect.sh"

- name: Copy BOOTABLE_report_generator.sh script to host
  copy:
    src: BOOTABLE_report_generator.R
    dest: "{{ root_path }}BOOTABLE_report_generator.sh"

########################
### Clean up history ###
########################
- name: Delete authorized_keys file of user centos
  command: history -c
